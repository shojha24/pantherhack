{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_dir = \"../input/celebrity-face-image-dataset/Celebrity Faces Dataset\"\nimport tensorflow as tf\nimport pathlib\n!pip install split-folders","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Split data as train and validation.**","metadata":{}},{"cell_type":"code","source":"import splitfolders\n\ndef split_data(data_path):\n    data = pathlib.Path(data_path)\n    splitfolders.ratio(data,output = \"Images/\",seed = 42,ratio = (0.8,0.2),group_prefix = None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"split_data(\"../input/celebrity-face-image-dataset/Celebrity Faces Dataset\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"All images will be scaled 1./255 to obtain 0-1 normalized image.Also use data augmentation.\"\"\"\ntrain_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1./255,rotation_range = 40,\n                                                                width_shift_range = 0.2,height_shift_range = 0.2,\n                                                                shear_range = 0.2,zoom_range = 0.2,horizontal_flip=True,\n                                                                vertical_flip = True,fill_mode = \"nearest\",\n                                                                )\nvalidation_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1./255)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_generator = train_datagen.flow_from_directory(\"Images/train\",target_size = (150,150),class_mode = \"categorical\",\n                                                   batch_size =64,subset = \"training\",seed = 42)\n\nvalidation_generator = validation_datagen.flow_from_directory(\"Images/val\",target_size = (150,150),\n                                                    class_mode = \"categorical\",batch_size = 64,\n                                                             seed = 42)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**CNN ARCHITECTURE WITH TRANSFER LEARNING**","metadata":{}},{"cell_type":"markdown","source":"**(1)Use Xception as base model.**","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.applications.xception import Xception\nbase_model = Xception(input_shape = (150,150,3),include_top = False,weights = \"imagenet\",pooling = \"max\")\n\"\"\"Freeze all layers to stop updating weights of imagenet.\"\"\"\nfor layer in base_model.layers:\n    layer.trainable = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**(2)Create an architecture to feed models.**","metadata":{}},{"cell_type":"code","source":"\"\"\"Here we can get add_11 as last layer.It means that we can start updating our weights after add_11 layer.\"\"\"\nlast_layer = base_model.get_layer(\"add_11\")\nprint(last_layer.output_shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes = os.listdir(base_dir)\n\"\"\"Flatten layer to reduce input dim to 1D.\"\"\"\nx = tf.keras.layers.BatchNormalization()(last_layer.output)\nx = tf.keras.layers.GlobalAveragePooling2D()(x)\n\"\"\"Add fully connected layers with 256 units.\"\"\"\nx = tf.keras.layers.Dense(units = 128,activation = \"relu\")(x)\n\"\"\"Add dropout layer.\"\"\"\nx = tf.keras.layers.Dropout(0.5)(x)\n\"\"\"Output Layer.\"\"\"\nx = tf.keras.layers.Dense(len(classes),activation = \"softmax\")(x)\n\"\"\"Here we can connect our model end to end.\"\"\"\nmodel = tf.keras.models.Model(base_model.input,x)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**COMPILE AND FIT MODEL.**","metadata":{}},{"cell_type":"code","source":"model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001),loss = \"categorical_crossentropy\",\n             metrics = [\"acc\"])\nclass myCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self,epoch,logs = {}):\n        if logs.get(\"acc\") - logs.get(\"val_acc\") > 0.1:\n            print(\"Model tends to be overfitting.Stop Training\")\n            self.model.stop_training = True\ncallback = myCallback()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_generator,epochs = 50,batch_size = 64,validation_data = validation_generator,\n                   callbacks = [callback],verbose = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**PLOT LOSS AND ACCURACY**","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nacc = history.history[\"acc\"]\nval_acc = history.history[\"val_acc\"]\nloss = history.history[\"loss\"];\nval_loss = history.history[\"val_loss\"]\nepochs = range(0,len(history.history[\"loss\"]))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(epochs,acc,label = \"Training Accuracy\")\nplt.plot(epochs,val_acc,label = \"Validation Accuracy\")\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(epochs,loss,label = \"Training Loss\")\nplt.plot(epochs,val_loss,label = \"Validation Loss\")\nplt.legend()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**SAVE MODEL AND LOAD MODEL**","metadata":{}},{"cell_type":"code","source":"model.save(\"celebrity_classification_TFL.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1 = tf.keras.models.load_model(\"celebrity_classification_TFL.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**GET THE IMAGES FROM INTERNET AND PROCESS THEM.**","metadata":{}},{"cell_type":"code","source":"from PIL import Image\nimport requests\nfrom io import BytesIO\nimport numpy as np","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_and_process(url):\n    response = requests.get(url)\n    img = Image.open(BytesIO(response.content))\n    img1 = img\n    \"\"\"Resize image to appropriate shape for model.\"\"\"\n    img = img.resize((150,150))\n    \"\"\"Convert img to numpy array,rescale it,expand dims and check vertically.\"\"\"\n    x = tf.keras.preprocessing.image.img_to_array(img)\n    x = x / 255.0\n    x = np.expand_dims(x,axis = 0)\n    img_tensor = np.vstack([x])\n    return img1,img_tensor\n    \n    \n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**FINAL :PREDICT IMAGE**","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt \nurl = \"https://ichef.bbci.co.uk/news/640/cpsprodpb/8012/production/_124368723_gettyimages-1357401691.jpg\"\nimg_1,test_img = get_and_process(url)\npred = model1.predict(test_img)\nclasses = list(train_generator.class_indices.keys())\nprint(f\"Prediction is : {classes[np.argmax(pred)]}\")\nplt.imshow(img_1)\nplt.show()\n\nprint(classes)\nprint(pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}